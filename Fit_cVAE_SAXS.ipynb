{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb96b1e",
   "metadata": {},
   "source": [
    "# Fit S(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de4512da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Huan Tung\n",
    "# National Tsing-Hua University\n",
    "# Aug 2021\n",
    "#\n",
    "# Fit the I(Q) curve using the S(Q) generated by pre-trained cVAE model\n",
    "# Infer potential parameters from optimized latent variables using GPR\n",
    "# tensorflow 2.6.0\n",
    "# sklearn 0.24.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61aa28",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ba8632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_SQ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffee5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import scipy.interpolate as interp\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062bd42d",
   "metadata": {},
   "source": [
    "Assign device (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "713a4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b2ae52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614d3c0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4071b",
   "metadata": {},
   "source": [
    "### Load SAXS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12708827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6f63105",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_SAXS = '../data/SAXSdata/Cys0.mat'\n",
    "SAXS_dict =  h5py.File(filename_SAXS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cf5eb71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q_SAXS = np.array(SAXS_dict['q'])\n",
    "Iq_SAXS = np.array(SAXS_dict['I'])\n",
    "SQ_SAXS = np.array(SAXS_dict['S'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65afa0c8",
   "metadata": {},
   "source": [
    "$Q\\cdot r_\\textrm{ave}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97782e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (np.arange(sq_dim)+1)*0.2\n",
    "q_rs = (np.arange(sq_dim)+1)*0.2\n",
    "q_rs_dim = q_rs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_dim = sq.shape[1]\n",
    "sample_train_dim = sq.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b1bb3d",
   "metadata": {},
   "source": [
    "Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1815949",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_eta = 1\n",
    "sq_rs = np.zeros((sample_train_dim,q_rs_dim),dtype='float32')\n",
    "for i in range(sample_train_dim):\n",
    "    qr_eta = q*r_eta\n",
    "    interpolating_function = interp.interp1d(qr_eta[3:],sq[i,3:],fill_value='extrapolate')\n",
    "    sq_rs[i,:] = interpolating_function(q_rs).astype(np.float32)\n",
    "sq_rs[sq_rs<=0] = sq_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a354d2",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum sq\n",
    "sq_min = np.exp(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c42a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    X_file = '../data/input_grid_all_GPR80.csv'\n",
    "    Y_file = '../data/target_grid_all.csv'\n",
    "else:\n",
    "    X_file = '../data/input_random_all_GPR80.csv'\n",
    "    Y_file = '../data/target_random_all.csv'\n",
    "    \n",
    "fX_test = open(X_file, 'r', encoding='utf-8-sig')\n",
    "sq_test = np.genfromtxt(fX_test, delimiter=',').astype(np.float32)\n",
    "sq_test[sq_test<=0] = sq_min\n",
    "\n",
    "fY_test = open(Y_file, 'r', encoding='utf-8-sig')\n",
    "target_test = np.genfromtxt(fY_test, delimiter=',').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_test = target_test[:, 0]\n",
    "kappa_test = target_test[:, 1]\n",
    "Z_test = target_test[:, 3]\n",
    "A_test = target_test[:, 2]\n",
    "lnZ_test = np.log(Z_test)\n",
    "lnA_test = np.log(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ed92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_dim = sq_test.shape[1]\n",
    "sample_test_dim = sq_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2519143b",
   "metadata": {},
   "source": [
    "$Q\\cdot r_\\textrm{ave}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636cee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (np.arange(sq_dim)+1)*0.2\n",
    "q_rs = (np.arange(sq_dim)+1)*0.2\n",
    "q_rs_dim = q_rs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19289f4d",
   "metadata": {},
   "source": [
    "Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_eta_test = 1\n",
    "sq_test_rs = np.zeros((sample_test_dim,q_rs_dim),dtype='float32')\n",
    "for i in range(sample_test_dim):\n",
    "    qr_eta = q*r_eta_test\n",
    "    interpolating_function_test = interp.interp1d(qr_eta[3:],sq_test[i,3:],\n",
    "                                                  fill_value='extrapolate',kind='linear')\n",
    "    sq_test_rs[i,:] = interpolating_function_test(q_rs)\n",
    "sq_test_rs[sq_test_rs<=0] = sq_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a708e8",
   "metadata": {},
   "source": [
    "### Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba833f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_length = 0\n",
    "sq_mask = sq_rs\n",
    "sq_test_mask = sq_test_rs\n",
    "\n",
    "for i in range(sample_train_dim):\n",
    "    sq_mask[i,0:mask_length] = sq_rs[i,mask_length]\n",
    "for i in range(sample_test_dim):\n",
    "    sq_test_mask[i,0:mask_length] = sq_test_mask[i,mask_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9f6a8",
   "metadata": {},
   "source": [
    "### Preprocess/Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31843470",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_scale = 6\n",
    "\n",
    "def f_inp(sq):\n",
    "    return np.log(sq)/exp_scale/2 + 0.5\n",
    "\n",
    "def f_out(predictions):\n",
    "    return np.exp((predictions*2-1)*exp_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e54b7",
   "metadata": {},
   "source": [
    "## Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da05e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim, sq_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        regularizer = None\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(sq_dim)),\n",
    "            tf.keras.layers.Reshape((sq_dim,1)),\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=32, kernel_size=3, strides=2, activation='relu',\n",
    "                kernel_regularizer = regularizer,\n",
    "                name='conv1d_en'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(\n",
    "                latent_dim + latent_dim, \n",
    "                kernel_regularizer = regularizer,\n",
    "                name='dense_en'),\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(\n",
    "                40*32, activation=tf.nn.relu, \n",
    "                kernel_regularizer = regularizer,\n",
    "                name='dense_de'),\n",
    "            tf.keras.layers.Reshape(target_shape=(40, 32)),\n",
    "            tf.keras.layers.Conv1DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same', activation='relu',\n",
    "                kernel_regularizer = regularizer,\n",
    "                name='conv1dtrs_de'),\n",
    "            tf.keras.layers.Conv1DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "            tf.keras.layers.Reshape((sq_dim,))\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = 0*tf.random.normal(shape=(1000, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "        \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28908a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "model = VAE(latent_dim, q_rs_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b1b35",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bdef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = './saved_model/SQ_cVAE_MSE_ns/'\n",
    "model_name = 'model_conv_stride2_exp6'\n",
    "export_name = export_path + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85318fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_sm = model.load_weights(export_name, by_name=False, skip_mismatch=False, options=None)\n",
    "reload_sm.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fee4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r = reload_sm._root\n",
    "#model_r.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da235a",
   "metadata": {},
   "source": [
    "### Loaded network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_r():\n",
    "    def __init__(self):\n",
    "        self.encoder = model_r.encoder\n",
    "        self.decoder = model_r.decoder\n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(1000, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "        \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits\n",
    "    \n",
    "M = VAE_r() # loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c547cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_mean(model,lv):\n",
    "    x = model.sample(lv)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def encoder_mean(model,x):\n",
    "    mean = model.encode(x)[0]\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b82c39",
   "metadata": {},
   "source": [
    "## Define functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_scale = 6\n",
    "\n",
    "@tf.function\n",
    "def f_inp_tf(sq):\n",
    "    return tf.math.log(sq)/exp_scale/2 + 0.5\n",
    "\n",
    "@tf.function\n",
    "def f_out_tf(predictions):\n",
    "    return tf.math.exp((predictions*2-1)*exp_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be670a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf(arg):\n",
    "    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardsphere(q,sigma=1):\n",
    "    R = to_tf(sigma/2)\n",
    "    P = (3*(tf.math.sin(q*R)-q*R*tf.math.cos(q*R))/(q*R)**3)**2\n",
    "    return P\n",
    "    \n",
    "    \n",
    "def interpolation_tf(q,x,scale):\n",
    "    qs = q*scale\n",
    "    x_interp = tfp.math.interp_regular_1d_grid(\n",
    "        to_tf(qs), tf.math.reduce_min(to_tf(q)), tf.math.reduce_max(to_tf(q)), x)\n",
    "    return x_interp\n",
    "\n",
    "def SQ_th(model, fp):\n",
    "    # structure factor\n",
    "    lv = tf.reshape(to_tf(fp[0:3]),(1,3))\n",
    "    x_logit = decoder_mean(model,lv)\n",
    "    S = f_out_tf(x_logit)\n",
    "    \n",
    "    # interpolation\n",
    "    #S_interp = interpolation_tf(q,S,fp[3])\n",
    "    \n",
    "    return S\n",
    "\n",
    "def IQ_th(model, fp):\n",
    "    # form factor\n",
    "    P = hardsphere(q,fp[3])\n",
    "    \n",
    "    # structure factor\n",
    "    lv = tf.reshape(to_tf(fp[0:3]),(1,3))\n",
    "    x_logit = decoder_mean(model,lv)\n",
    "    S = f_out_tf(x_logit)\n",
    "    \n",
    "    # I(Q)\n",
    "    if fit_SQ==1:\n",
    "        IQ_th = S\n",
    "    else:\n",
    "        IQ_th = S*P\n",
    "    \n",
    "    # interpolation\n",
    "    IQ_th_interp = interpolation_tf(q,IQ_th,fp[3])\n",
    "    return IQ_th_interp\n",
    "\n",
    "def fit_loss(model, x, fp):\n",
    "    x_th = IQ_th(model, fp)\n",
    "    \n",
    "    # mean-square error\n",
    "    err = tf.reduce_mean((tf.math.log(x_th)-tf.math.log(x))**2)\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, x, fp, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = fit_loss(model, x, fp)\n",
    "    gradients = tape.gradient(loss, fp)\n",
    "    optimizer.apply_gradients(zip(gradients, fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "def generate_image(model, IQ_exp, fp, epoch=0):\n",
    "    error = fit_loss(model, IQ_exp, fp)\n",
    "    IQ_th_current = IQ_th(model, fp)[0,:]\n",
    "    \n",
    "    #display.clear_output(wait=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "    \n",
    "    plt.plot(q,IQ_exp,'sk')\n",
    "    #plt.plot(q,IQ_th_current,'b')\n",
    "    \n",
    "    q_new = np.logspace(np.log10(0.2),np.log10(16),500)\n",
    "    spl = interpolate.InterpolatedUnivariateSpline(q,IQ_th_current)\n",
    "    IQ_th_new = spl(q_new)\n",
    "    \n",
    "    plt.plot(q_new,IQ_th_new,'b')\n",
    "    \n",
    "    fp_s = (np.matmul([fp[0:3],]-z_mean,U)*sgn)[0]\n",
    "    \n",
    "    plt.text(0.6,0.96,'MSE = {:.2e}'.format(error),transform=ax.transAxes)\n",
    "    plt.text(0.8,0.96,'lv[0] = {:+.2f}'.format(fp_s[0]),transform=ax.transAxes)\n",
    "    plt.text(0.8,0.90,'lv[1] = {:+.2f}'.format(fp_s[1]),transform=ax.transAxes)\n",
    "    plt.text(0.8,0.84,'lv[2] = {:+.2f}'.format(fp_s[2]),transform=ax.transAxes)\n",
    "    plt.text(0.8,0.78,'$\\sigma$ = {:+.2f}'.format(fp[3].numpy()),transform=ax.transAxes)\n",
    "    plt.xscale('log')\n",
    "    #plt.yscale('log')\n",
    "    plt.xlim(3, 16)\n",
    "    #plt.ylim(3e-4, 0.3)\n",
    "    plt.xlabel('$Q$')\n",
    "    plt.ylabel('$I(Q)$')\n",
    "    \n",
    "    pngname = './figures_SQ_cVAE_MSE_ns/fit/fit_{:04d}.png'\n",
    "    plt.savefig(pngname.format(epoch))\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "    #print('epoch = {:04d}'.format(epoch))\n",
    "    #time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60110b24",
   "metadata": {},
   "source": [
    "## Pick an I(Q) and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34972226",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index_test = 16609 #9202\n",
    "sigma_test = 1.00\n",
    "SQ_exp = sq_test_mask[index_test,:]\n",
    "lv_GT = encoder_mean(M,to_tf(f_inp(SQ_exp.reshape((1,80)))))\n",
    "\n",
    "SQ_exp = to_tf(SQ_exp)\n",
    "P = hardsphere(q,1)\n",
    "\n",
    "if fit_SQ==1:\n",
    "    IQ_exp = SQ_exp\n",
    "else:\n",
    "    IQ_exp = SQ_exp*P\n",
    "    \n",
    "IQ_exp = interpolation_tf(q,IQ_exp,sigma_test)\n",
    "\n",
    "fp_GT = [lv_GT[0,0],lv_GT[0,1],lv_GT[0,2],to_tf(sigma_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59af526",
   "metadata": {},
   "source": [
    "### Initial value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd596563",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(export_path +'lv_SVD_exp6.npz') as data:\n",
    "    z_mean = data['z_mean']\n",
    "    U = data['U']\n",
    "    sgn = data['sgn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.constant(\"Initial Guess\")\n",
    "def initial_guess_transform(lv_s = [0,0,0]):\n",
    "    lv = to_tf(np.matmul(lv_s*sgn,U.T) + z_mean)\n",
    "    return lv\n",
    "\n",
    "sigma_i = tf.constant(1.00)\n",
    "lv0_i = tf.constant(initial_guess_transform()[0])\n",
    "lv1_i = tf.constant(initial_guess_transform()[1])\n",
    "lv2_i = tf.constant(initial_guess_transform()[2])\n",
    "\n",
    "# constraint=lambda t: tf.clip_by_value(t, \"Lower Bound\", \"Upper Bound\")\n",
    "sigma = tf.Variable(sigma_i, name='sigma', dtype=tf.float32, \n",
    "                    constraint=lambda t: tf.clip_by_value(t, 1.0, 1.0))\n",
    "lv0 = tf.Variable(lv0_i, name='lv0', dtype=tf.float32, \n",
    "                 constraint=lambda t: tf.clip_by_value(t, -10, 10))\n",
    "lv1 = tf.Variable(lv1_i, name='lv1', dtype=tf.float32, \n",
    "                 constraint=lambda t: tf.clip_by_value(t, -10, 10))\n",
    "lv2 = tf.Variable(lv2_i, name='lv2', dtype=tf.float32, \n",
    "                 constraint=lambda t: tf.clip_by_value(t, -10, 10))\n",
    "\n",
    "fp = [lv0,lv1,lv2,sigma]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f24e4a",
   "metadata": {},
   "source": [
    "---\n",
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a98b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_image(M, IQ_exp, fp)\n",
    "epochs = 400\n",
    "\n",
    "import progressbar\n",
    "bar = progressbar.ProgressBar(maxval=epochs, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "start_time = time.time()\n",
    "\n",
    "fp_epoch = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_step(M, IQ_exp, fp, optimizer)\n",
    "    \n",
    "    bar.update(epoch)\n",
    "    #sleep(0.1)\n",
    "    \n",
    "    # generate image\n",
    "    if 1:\n",
    "        if epoch%10 == 0:\n",
    "            generate_image(M, IQ_exp, fp, epoch)\n",
    "    \n",
    "    fp_current = [fp[0].numpy(),fp[1].numpy(),fp[2].numpy(),fp[3].numpy()]\n",
    "    fp_epoch.append(fp_current)\n",
    "\n",
    "end_time = time.time()\n",
    "bar.finish()\n",
    "\n",
    "print('time elapsed = {:0.2f}s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7696fc",
   "metadata": {},
   "source": [
    "### Display animated GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83077a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = './figures_SQ_cVAE_MSE_ns/fit/fit.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('./figures_SQ_cVAE_MSE_ns/fit/fit_*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee747d1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0e1e2",
   "metadata": {},
   "source": [
    "### fitting parameters summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_s = (np.matmul([fp[0:3],]-z_mean,U)*sgn)[0]\n",
    "fp_GT_s = (np.matmul([fp_GT[0:3],]-z_mean,U)*sgn)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c48d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string_fp    = 'fp      = {:0.4f}, {:0.4f}, {:0.4f}\\n'.format(fp[0].numpy(),fp[1].numpy(),fp[2].numpy())\n",
    "string_fp_GT = 'fp_GT   = {:0.4f}, {:0.4f}, {:0.4f}\\n'.format(fp_GT[0].numpy(),fp_GT[1].numpy(),fp_GT[2].numpy())\n",
    "string_fp_s    = 'fp_s    = {:0.4f}, {:0.4f}, {:0.4f}\\n'.format(fp_s[0],fp_s[1],fp_s[2])\n",
    "string_fp_GT_s = 'fp_GT_s = {:0.4f}, {:0.4f}, {:0.4f}\\n'.format(fp_GT_s[0],fp_GT_s[1],fp_GT_s[2])\n",
    "print(string_fp + string_fp_GT + string_fp_s + string_fp_GT_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83492fe",
   "metadata": {},
   "source": [
    "## Test GPR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b2df1",
   "metadata": {},
   "source": [
    "### load trained GPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6adf49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = (eta_test,kappa_test,lnA_test)\n",
    "parameters_GP = np.vstack(parameters).T\n",
    "index_eta = np.arange(sq_test.shape[0])\n",
    "\n",
    "parameters_GT = parameters_GP[index_test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e77d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3435b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path_GPR = './saved_model/GPR/' \n",
    "model_name_GPR_eta = 'sklearn/SQ_GPR_eta'\n",
    "model_name_GPR_kappa = 'sklearn/SQ_GPR_kappa'\n",
    "model_name_GPR_lnA = 'sklearn/SQ_GPR_lnA'\n",
    "export_name_GPR_eta = export_path_GPR + model_name_GPR_eta\n",
    "export_name_GPR_kappa = export_path_GPR + model_name_GPR_kappa\n",
    "export_name_GPR_lnA = export_path_GPR + model_name_GPR_lnA\n",
    "gp_eta = joblib.load(export_name_GPR_eta)\n",
    "gp_kappa = joblib.load(export_name_GPR_kappa)\n",
    "gp_lnA = joblib.load(export_name_GPR_lnA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_eta = gp_eta.predict(SQ_th(M, fp).numpy(), return_std=True)\n",
    "predict_kappa = gp_kappa.predict(SQ_th(model, fp).numpy(), return_std=True)\n",
    "predict_lnA = gp_lnA.predict(SQ_th(M, fp).numpy(), return_std=True)\n",
    "parameters_predict = [predict_eta,predict_kappa,predict_lnA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19f872",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Ground truth: \\n--- eta = {:0.4f} \\n--- kappa = {:0.4f} \\n--- lnA = {:0.4f}\\n'\n",
    "      .format(parameters_GT[0],parameters_GT[1],parameters_GT[2]))\n",
    "print('Predictions: \\n--- eta = {:0.4f} +- {:0.4f} \\n--- kappa = {:0.4f} +- {:0.4f} \\n--- lnA = {:0.4f} +- {:0.4f}'\n",
    "      .format(parameters_predict[0][0][0],parameters_predict[0][1][0],\n",
    "              parameters_predict[1][0][0],parameters_predict[1][1][0],\n",
    "              parameters_predict[2][0][0],parameters_predict[2][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7568b5",
   "metadata": {},
   "source": [
    "### $V(r)$  \n",
    "Sample $V(r)$ and determine the confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba597e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_potential(parameters_predict,r,ur_hc):\n",
    "    n_sample = 100\n",
    "    kappa = parameters_predict[1][0][0]\n",
    "    kappa_std = parameters_predict[1][1][0]\n",
    "    lnA = parameters_predict[2][0][0]\n",
    "    lnA_std = parameters_predict[2][1][0]\n",
    "    \n",
    "    ur_sample = np.zeros((tf.size(r),n_sample))\n",
    "    for i in range(n_sample):\n",
    "        kappa_sample = np.random.normal()*(kappa_std) + kappa\n",
    "        lnA_sample = np.random.normal()*(lnA_std) + lnA\n",
    "        ur_sample[:,i] = np.exp(lnA_sample)*np.exp(-(r-1)/kappa_sample)/r + ur_hc\n",
    "        \n",
    "    return ur_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.linspace(0.01, 2.0, 200)\n",
    "ur_hc = 4*500*((2**(1/6)/r)**12-(2**(1/6)/r)**6-0.25)\n",
    "ur_hc[r>=1] = 0\n",
    "\n",
    "ur_GT = np.exp(parameters_GT[2])*np.exp(-(r-1.0)/parameters_GT[1])/r + ur_hc\n",
    "ur_predict = np.exp(parameters_predict[2][0][0])*np.exp(-(r-1.0)/parameters_predict[1][0][0])/r + ur_hc\n",
    "ur_sample = sample_potential(parameters_predict,r,ur_hc)\n",
    "\n",
    "ur_std = np.std(ur_sample,axis=1)\n",
    "ur_mean = np.mean(ur_sample,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09240c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.fill_between(r,ur_mean+ur_std,ur_mean-ur_std,color='c',alpha=0.5)\n",
    "ax.plot(r,ur_GT,'k')\n",
    "ax.plot(r,ur_mean,'b')\n",
    "ax.set_xlim(0.9,2.0)\n",
    "ax.set_ylim(-0.1,20)\n",
    "ax.set_xlabel(r'$r/D$')\n",
    "ax.set_ylabel(r'$V(r/D)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde975a3",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85cd57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = to_tf(f_inp(sq_mask))\n",
    "mean, logvar = model.encode(x)\n",
    "z = model.reparameterize(mean, logvar)\n",
    "x_logit = model.sample(z)\n",
    "z = z.numpy()\n",
    "zc = z-z_mean\n",
    "F = zc.T\n",
    "zs = np.matmul(zc,U)*sgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f98ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "hull = ConvexHull(zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_zs = np.max(zs,axis = 0)-np.min(zs,axis = 0)\n",
    "d_z = np.max(z,axis = 0)-np.min(z,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = (eta,kappa,lnA)\n",
    "index_eta = np.arange(sq.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbf725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53607564",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "#ax.scatter(zs[index_eta,0], zs[index_eta,1], zs[index_eta,2], \n",
    "           #c=parameters[0][index_eta],\n",
    "           #s=1)\n",
    "        \n",
    "#for s in hull.simplices:\n",
    "    #s = np.append(s, s[0])  # Here we cycle back to the first coordinate\n",
    "    #ax.plot(zs[s, 0], zs[s, 1], zs[s, 2], \"k-\", alpha=0.1)\n",
    "\n",
    "for i in range(len(fp_epoch)):\n",
    "    if i==0:\n",
    "        continue\n",
    "        \n",
    "    lv_i = fp_epoch[i][0:3]\n",
    "    lv_i_s = (np.matmul([lv_i,]-z_mean,U)*sgn)[0]\n",
    "    lv_ip = fp_epoch[i-1][0:3]\n",
    "    lv_ip_s = (np.matmul([lv_ip,]-z_mean,U)*sgn)[0]\n",
    "    \n",
    "    alpha0 = 0.1\n",
    "    ax.plot([lv_ip_s[0],lv_i_s[0]], [lv_ip_s[1],lv_i_s[1]], [lv_ip_s[2],lv_i_s[2]],\n",
    "            '-r',alpha=alpha0+(1-alpha0)*(i/len(fp_epoch)))\n",
    "\n",
    "ax.scatter(fp_GT_s[0], fp_GT_s[1], fp_GT_s[2], \n",
    "        c='k',\n",
    "        s=50,\n",
    "        marker='*')\n",
    "\n",
    "ax.view_init(elev=30, azim=-115)\n",
    "ax.set_xlabel('lv[0]')\n",
    "ax.set_ylabel('lv[1]')\n",
    "ax.set_zlabel('lv[2]')\n",
    "ax.set_box_aspect([d_zs[0],d_zs[1],d_zs[2]])\n",
    "\n",
    "scatter_name = './figures_SQ_cVAE_MSE_ns/lvsc3D_eta.png'\n",
    "plt.savefig(scatter_name.format(epoch))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(q,SQ_exp.numpy().reshape(80),'-k')\n",
    "plt.plot(q,SQ_th(M, fp).numpy().reshape(80),'-b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a380e",
   "metadata": {},
   "source": [
    "## Under Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32e70d",
   "metadata": {},
   "source": [
    "print(U)\n",
    "print(z_mean)\n",
    "print(sgn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0ada6",
   "metadata": {},
   "source": [
    "with np.load(export_path +'lv_SVD_batch32.npz') as data:\n",
    "    z_mean = data['z_mean']\n",
    "    U = data['U']\n",
    "    sgn = data['sgn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958e95d1",
   "metadata": {},
   "source": [
    "export_path_GPR = './saved_model/GPR/' \n",
    "model_name_GPR_eta = 'sklearn/model_GPR_eta'\n",
    "model_name_GPR_kappa = 'sklearn/model_GPR_kappa'\n",
    "model_name_GPR_lnA = 'sklearn/model_GPR_lnA'\n",
    "export_name_GPR_eta = export_path_GPR + model_name_GPR_eta\n",
    "export_name_GPR_kappa = export_path_GPR + model_name_GPR_kappa\n",
    "export_name_GPR_lnA = export_path_GPR + model_name_GPR_lnA\n",
    "gp_eta = joblib.load(export_name_GPR_eta)\n",
    "gp_kappa = joblib.load(export_name_GPR_kappa)\n",
    "gp_lnA = joblib.load(export_name_GPR_lnA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cfaa57",
   "metadata": {},
   "source": [
    "predict_eta = gp_eta.predict(fp_p, return_std=True)\n",
    "predict_kappa = gp_kappa.predict(fp_p, return_std=True)\n",
    "predict_lnA = gp_lnA.predict(fp_p, return_std=True)\n",
    "parameters_predict = [predict_eta,predict_kappa,predict_lnA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be435b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
