{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb96b1e",
   "metadata": {},
   "source": [
    "# Fit S(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4512da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Huan Tung\n",
    "# National Tsing-Hua University\n",
    "# Aug 2021\n",
    "#\n",
    "# This notebook is based on the example of Convolutional Variational Autoencoder (CVAE)\n",
    "# on tensorflow.org/tutorials/generative/cvae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61aa28",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import scipy.interpolate as interp\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062bd42d",
   "metadata": {},
   "source": [
    "Assign device (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ae52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614d3c0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a354d2",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum sq\n",
    "sq_min = np.exp(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c42a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    X_file = '../data/input_grid_all_GPR80.csv'\n",
    "    Y_file = '../data/target_grid_all.csv'\n",
    "else:\n",
    "    X_file = '../data/input_random_all_GPR80.csv'\n",
    "    Y_file = '../data/target_random_all.csv'\n",
    "    \n",
    "fX_test = open(X_file, 'r', encoding='utf-8-sig')\n",
    "sq_test = np.genfromtxt(fX_test, delimiter=',').astype(np.float32)\n",
    "sq_test[sq_test<=0] = sq_min\n",
    "\n",
    "fY_test = open(Y_file, 'r', encoding='utf-8-sig')\n",
    "target_test = np.genfromtxt(fY_test, delimiter=',').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_test = target_test[:, 0]\n",
    "kappa_test = target_test[:, 1]\n",
    "Z_test = target_test[:, 3]\n",
    "A_test = target_test[:, 2]\n",
    "lnZ_test = np.log(Z_test)\n",
    "lnA_test = np.log(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ed92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_dim = sq_test.shape[1]\n",
    "sample_test_dim = sq_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2519143b",
   "metadata": {},
   "source": [
    "$Q\\cdot r_\\textrm{ave}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636cee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (np.arange(sq_dim)+1)*0.2\n",
    "q_rs = (np.arange(sq_dim)+1)*0.2\n",
    "q_rs_dim = q_rs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19289f4d",
   "metadata": {},
   "source": [
    "Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_eta_test = 1\n",
    "sq_test_rs = np.zeros((sample_test_dim,q_rs_dim),dtype='float32')\n",
    "for i in range(sample_test_dim):\n",
    "    qr_eta = q*r_eta_test\n",
    "    interpolating_function_test = interp.interp1d(qr_eta[3:],sq_test[i,3:],\n",
    "                                                  fill_value='extrapolate',kind='linear')\n",
    "    sq_test_rs[i,:] = interpolating_function_test(q_rs)\n",
    "sq_test_rs[sq_test_rs<=0] = sq_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a708e8",
   "metadata": {},
   "source": [
    "### Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba833f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_length = 0\n",
    "sq_test_mask = sq_test_rs\n",
    "\n",
    "for i in range(sample_test_dim):\n",
    "    sq_test_mask[i,0:mask_length] = sq_test_mask[i,mask_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9f6a8",
   "metadata": {},
   "source": [
    "### Preprocess/Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31843470",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_scale = 3\n",
    "\n",
    "def f_inp(sq):\n",
    "    return np.log(sq)/exp_scale/2 + 0.5\n",
    "\n",
    "def f_out(predictions):\n",
    "    return np.exp((predictions*2-1)*exp_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a740bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf(arg):\n",
    "    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e54b7",
   "metadata": {},
   "source": [
    "## Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da05e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim, sq_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        regularizer = None\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(sq_dim)),\n",
    "            tf.keras.layers.Reshape((sq_dim,1)),\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=32, kernel_size=3, strides=2, activation='relu',\n",
    "                kernel_regularizer = regularizer,\n",
    "                name='conv1d_en'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(\n",
    "                latent_dim + latent_dim, \n",
    "                kernel_regularizer = regularizer,\n",
    "                name='dense_en'),\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(\n",
    "                40*32, activation=tf.nn.relu, \n",
    "                kernel_regularizer = regularizer,\n",
    "                name='dense_de'),\n",
    "            tf.keras.layers.Reshape(target_shape=(40, 32)),\n",
    "            tf.keras.layers.Conv1DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same', activation='relu',\n",
    "                kernel_regularizer = regularizer,\n",
    "                name='conv1dtrs_de'),\n",
    "            tf.keras.layers.Conv1DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "            tf.keras.layers.Reshape((sq_dim,))\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(1000, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "        \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28908a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "model = VAE(latent_dim, q_rs_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b1b35",
   "metadata": {},
   "source": [
    "## Load and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bdef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = './saved_model/SQ_cVAE_MSE_ns/'\n",
    "model_name = 'model_conv_stride2_GPR'\n",
    "export_name = export_path + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85318fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_sm = model.load_weights(export_name, by_name=False, skip_mismatch=False, options=None)\n",
    "reload_sm.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fee4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r = reload_sm._root\n",
    "#model_r.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da235a",
   "metadata": {},
   "source": [
    "### Loaded network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_r():\n",
    "    def __init__(self):\n",
    "        self.encoder = model_r.encoder\n",
    "        self.decoder = model_r.decoder\n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = 0*tf.random.normal(shape=(1000, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "        \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5)*0 + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits\n",
    "    \n",
    "M = VAE_r() # loaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c738d824",
   "metadata": {},
   "source": [
    "## Define functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(model,lv):\n",
    "    z = model.reparameterize(lv, 0*lv)\n",
    "    x = model.sample(z)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def encoder(model,x):\n",
    "    mean = model.encode(x)[0]\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_loss(model, IQ_exp, fp):\n",
    "    # form factor\n",
    "    P = np.ones(IQ_exp.shape)\n",
    "    \n",
    "    # structure factor\n",
    "    lv = tf.reshape(to_tf(fp[0:3]),(1,3))\n",
    "    S = decoder(model,lv)\n",
    "    \n",
    "    # mean-square error\n",
    "    IQ_th = P*S\n",
    "    \n",
    "    err = tf.reduce_mean((IQ_th-IQ_exp)**2)\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe9aade",
   "metadata": {},
   "source": [
    "## pick an I(Q) and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6be212",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_guess = (eta_test==0.03)&(kappa_test==0.2)&(A_test==10)\n",
    "IQ_guess = f_inp(sq_test_mask[i_guess,:])\n",
    "IQ_guess = to_tf(IQ_guess)\n",
    "lv_guess = encoder(M,IQ_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf655aa",
   "metadata": {},
   "source": [
    "### initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8461768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigma = tf.Variable(initial_value=1.0)\n",
    "lv0 = tf.Variable(initial_value=0.0)\n",
    "lv1 = tf.Variable(initial_value=0.0)\n",
    "lv2 = tf.Variable(initial_value=0.0)\n",
    "fp = [lv0,lv1,lv2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66affbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IQ_exp = f_inp(sq_test_mask[15000,:])\n",
    "IQ_exp = to_tf(IQ_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c47eba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "optimizer = tf.keras.optimizers.Adam(1e-1)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = fit_loss(M, IQ_exp, fp)\n",
    "    gradients = tape.gradient(loss, fp)\n",
    "    optimizer.apply_gradients(zip(gradients, fp))\n",
    "    end_time = time.time()   \n",
    "        \n",
    "    lv_fit = tf.reshape(to_tf([lv0,lv1,lv2]),(1,3))\n",
    "    S = decoder(M,lv_fit)[0,:]\n",
    "    error = np.mean((f_out(IQ_exp)-f_out(S))**2)\n",
    "    \n",
    "    display.clear_output(wait=False)\n",
    "    \n",
    "    #print(error)\n",
    "    plt.plot(f_out(IQ_exp),'k')\n",
    "    plt.plot(f_out(S),'b')\n",
    "    plt.text(60,0.375,'MSE = {:.5f}'.format(error))\n",
    "    plt.text(60,0.25,'lv[0] = {:.2f}'.format(lv0.numpy()))\n",
    "    plt.text(60,0.125,'lv[1] = {:.2f}'.format(lv1.numpy()))\n",
    "    plt.text(60,0,'lv[2] = {:.2f}'.format(lv2.numpy()))\n",
    "    \n",
    "    pngname = './figures_SQ_cVAE_MSE_ns/fit_{:04d}.png'\n",
    "    plt.savefig(pngname.format(epoch))\n",
    "    plt.show()\n",
    "    #time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a497589",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = './figures_SQ_cVAE_MSE_ns/Fit.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('./figures_SQ_cVAE_MSE_ns/fit_*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d3281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
