{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a3263b5",
   "metadata": {},
   "source": [
    "# Variational Autoencoder for S(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Huan Tung\n",
    "# National Tsing-Hua University\n",
    "# Aug 2021\n",
    "#\n",
    "# This notebook is based on the example of Convolutional Variational Autoencoder (CVAE)\n",
    "# on tensorflow.org/tutorials/generative/cvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use convolution layer\n",
    "# Sigmoid function output from network\n",
    "# ln(S(Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff2aac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de81871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import scipy.interpolate as interp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d429c5d",
   "metadata": {},
   "source": [
    "Assign device (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793585f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7000db",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdfec0d",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum sq\n",
    "sq_min = np.exp(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    X_file = '../data/input_grid_all_GPR80.csv'\n",
    "    Y_file = '../data/target_grid_all.csv'\n",
    "else:\n",
    "    X_file = '../data/input_random_all_GPR80.csv'\n",
    "    Y_file = '../data/target_random_all.csv'\n",
    "    \n",
    "fX = open(X_file, 'r', encoding='utf-8-sig')\n",
    "sq = np.genfromtxt(fX, delimiter=',').astype(np.float32)\n",
    "sq[sq<=0] = sq_min\n",
    "\n",
    "fY = open(Y_file, 'r', encoding='utf-8-sig')\n",
    "target = np.genfromtxt(fY, delimiter=',').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d40b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    sq = np.vstack((sq[0:7500,:],sq))\n",
    "    target = np.vstack((target[0:7500,:],target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e54076",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = target[:,0]\n",
    "kappa = target[:,1]\n",
    "Z = target[:,3]\n",
    "A = target[:,2]\n",
    "lnZ = np.log(Z)\n",
    "lnA = np.log(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_dim = sq.shape[1]\n",
    "sample_train_dim = sq.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65afa0c8",
   "metadata": {},
   "source": [
    "$Q\\cdot r_\\textrm{ave}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97782e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (np.arange(sq_dim)+1)*0.2\n",
    "q_rs = (np.arange(sq_dim)+1)*0.2\n",
    "q_rs_dim = q_rs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b1bb3d",
   "metadata": {},
   "source": [
    "Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1815949",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_eta = (eta/np.pi*6)**(-1/3)\n",
    "sq_rs = np.zeros((sample_train_dim,q_rs_dim),dtype='float32')\n",
    "for i in range(sample_train_dim):\n",
    "    qr_eta = q*r_eta[i]\n",
    "    interpolating_function = interp.interp1d(qr_eta[3:],sq[i,3:],fill_value='extrapolate')\n",
    "    sq_rs[i,:] = interpolating_function(q_rs).astype(np.float32)\n",
    "sq_rs[sq_rs<=0] = sq_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b19342",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51cf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    X_file = '../data/input_grid_all_GPR80.csv'\n",
    "    Y_file = '../data/target_grid_all.csv'\n",
    "else:\n",
    "    X_file = '../data/input_random_all_GPR80.csv'\n",
    "    Y_file = '../data/target_random_all.csv'\n",
    "    \n",
    "fX_test = open(X_file, 'r', encoding='utf-8-sig')\n",
    "sq_test = np.genfromtxt(fX_test, delimiter=',').astype(np.float32)\n",
    "sq_test[sq_test<=0] = sq_min\n",
    "\n",
    "fY_test = open(Y_file, 'r', encoding='utf-8-sig')\n",
    "target_test = np.genfromtxt(fY_test, delimiter=',').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f4c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_test = target_test[:, 0]\n",
    "kappa_test = target_test[:, 1]\n",
    "Z_test = target_test[:, 3]\n",
    "A_test = target_test[:, 2]\n",
    "lnZ_test = np.log(Z_test)\n",
    "lnA_test = np.log(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e7f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_dim = sq_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bae3b5",
   "metadata": {},
   "source": [
    "Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a3032",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_eta_test = (eta_test/np.pi*6)**(-1/3)\n",
    "sq_test_rs = np.zeros((sample_test_dim,q_rs_dim),dtype='float32')\n",
    "for i in range(sample_test_dim):\n",
    "    qr_eta = q*r_eta_test[i]\n",
    "    interpolating_function_test = interp.interp1d(qr_eta[3:],sq_test[i,3:],fill_value='extrapolate')\n",
    "    sq_test_rs[i,:] = interpolating_function_test(q_rs)\n",
    "sq_test_rs[sq_test_rs<=0] = sq_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e28a7",
   "metadata": {},
   "source": [
    "### Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f8c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_length = 0\n",
    "sq_mask = sq_rs\n",
    "sq_test_mask = sq_test_rs\n",
    "\n",
    "for i in range(sample_train_dim):\n",
    "    sq_mask[i,0:mask_length] = sq_rs[i,mask_length]\n",
    "for i in range(sample_test_dim):\n",
    "    sq_test_mask[i,0:mask_length] = sq_test_mask[i,mask_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b255a047",
   "metadata": {},
   "source": [
    "### Preprocess/Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2aec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_scale = 3\n",
    "\n",
    "def f_inp(sq):\n",
    "    return np.log(sq)/exp_scale/2 + 0.5\n",
    "\n",
    "def f_out(predictions):\n",
    "    return np.exp((predictions*2-1)*exp_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7518bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf(arg):\n",
    "    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78963db5",
   "metadata": {},
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3b25e",
   "metadata": {},
   "source": [
    "Merge set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed243a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = sq.shape[0]\n",
    "test_size = sq_test.shape[0]\n",
    "if 1:\n",
    "    n_merge = 10000\n",
    "    train_size = train_size + n_merge\n",
    "    rng = np.random.default_rng()\n",
    "    index = np.arange(sq_test.shape[0])\n",
    "    rng.shuffle(index)\n",
    "    sq_mask = np.vstack((sq_mask,sq_test_mask[index[0:n_merge],:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e85668",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "batch_size_test = 16\n",
    "\n",
    "train_dataset = (tf.data.Dataset.from_tensor_slices(f_inp(sq_mask))\n",
    "                 .shuffle(train_size).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(f_inp(sq_test_mask))\n",
    "                .shuffle(test_size, seed=6174).batch(sample_test_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe65c00",
   "metadata": {},
   "source": [
    "## Define the encoder and decoder networks with *tf.keras.Sequential*\n",
    "\n",
    "In this VAE example, use two small ConvNets for the encoder and decoder networks. In the literature, these networks are also referred to as inference/recognition and generative models respectively. Use `tf.keras.Sequential` to simplify implementation. Let $x$ and $z$ denote the observation and latent variable respectively in the following descriptions.\n",
    "\n",
    "### Encoder network\n",
    "This defines the approximate posterior distribution $q(z|x)$, which takes as input an observation and outputs a set of parameters for specifying the conditional distribution of the latent representation $z$. \n",
    "In this example, simply model the distribution as a diagonal Gaussian, and the network outputs the mean and log-variance parameters of a factorized Gaussian. \n",
    "Output log-variance instead of the variance directly for numerical stability.\n",
    "\n",
    "### Decoder network \n",
    "This defines the conditional distribution of the observation $p(x|z)$, which takes a latent sample $z$ as input and outputs the parameters for a conditional distribution of the observation.\n",
    "Model the latent distribution prior $p(z)$ as a unit Gaussian.\n",
    "\n",
    "### Reparameterization trick\n",
    "To generate a sample $z$ for the decoder during training, you can sample from the latent distribution defined by the parameters outputted by the encoder, given an input observation $x$.\n",
    "However, this sampling operation creates a bottleneck because backpropagation cannot flow through a random node.\n",
    "\n",
    "To address this, use a reparameterization trick.\n",
    "In our example, you approximate $z$ using the decoder parameters and another parameter $\\epsilon$ as follows:\n",
    "\n",
    "$$z = \\mu + \\sigma \\odot \\epsilon$$\n",
    "\n",
    "where $\\mu$ and $\\sigma$ represent the mean and standard deviation of a Gaussian distribution respectively. They can be derived from the decoder output. The $\\epsilon$ can be thought of as a random noise used to maintain stochasticity of $z$. Generate $\\epsilon$ from a standard normal distribution.\n",
    "\n",
    "The latent variable $z$ is now generated by a function of $\\mu$, $\\sigma$ and $\\epsilon$, which would enable the model to backpropagate gradients in the encoder through $\\mu$ and $\\sigma$ respectively, while maintaining stochasticity through $\\epsilon$.\n",
    "\n",
    "### Network architecture\n",
    "For the encoder network, use two convolutional layers followed by a fully-connected layer. In the decoder network, mirror this architecture by using a fully-connected layer followed by three convolution transpose layers (a.k.a. deconvolutional layers in some contexts). Note, it's common practice to avoid using batch normalization when training VAEs, since the additional stochasticity due to using mini-batches may aggravate instability on top of the stochasticity from sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e23c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim, sq_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        regularizer = None\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(sq_dim)),\n",
    "            tf.keras.layers.Reshape((sq_dim,1)),\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=32, kernel_size=3, strides=2, activation='relu',\n",
    "                kernel_regularizer = regularizer,\n",
    "                name='conv1d_en'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(\n",
    "                latent_dim + latent_dim, \n",
    "                kernel_regularizer = regularizer,\n",
    "                name='dense_en'),\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(\n",
    "                40*32, activation=tf.nn.relu, \n",
    "                kernel_regularizer = regularizer,\n",
    "                name='dense_de'),\n",
    "            tf.keras.layers.Reshape(target_shape=(40, 32)),\n",
    "            tf.keras.layers.Conv1DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same', activation='relu',\n",
    "                kernel_regularizer = regularizer,\n",
    "                name='conv1dtrs_de'),\n",
    "            tf.keras.layers.Conv1DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "            tf.keras.layers.Reshape((sq_dim,))\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(1000, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "        \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a1b9b5",
   "metadata": {},
   "source": [
    "## Define the loss function and the optimizer\n",
    "\n",
    "VAEs train by maximizing the evidence lower bound (ELBO) on the marginal log-likelihood:\n",
    "\n",
    "$$\\log p(x) \\ge \\text{ELBO} = \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p(x, z)}{q(z|x)}\\right].$$\n",
    "\n",
    "In practice, optimize the single sample Monte Carlo estimate of this expectation:\n",
    "\n",
    "$$\\log p(x| z) + \\log p(z) - \\log q(z|x),$$\n",
    "where $z$ is sampled from $q(z|x)$.\n",
    "\n",
    "Note: You could also analytically compute the KL term, but here you incorporate all three terms in the Monte Carlo estimator for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45b34c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def loss_l1(weights):\n",
    "    loss = tf.reduce_mean(tf.math.abs(weights))\n",
    "    return loss\n",
    "\n",
    "def loss_l2(weights):\n",
    "    loss = tf.reduce_mean((weights)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a377c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(5e-5)\n",
    "#optimizer = tf.keras.optimizers.Adadelta(1e-3)\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    x_out = x-0.5\n",
    "    x_logit_out = x_logit-0.5\n",
    "    \n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_out, labels=x_logit_out)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    elbo = -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "    \n",
    "    predictions_x = model.sample(z)\n",
    "    err = tf.reduce_mean((predictions_x-x)**2)\n",
    "    \n",
    "    \n",
    "    if 0:\n",
    "        # regularization loss\n",
    "        kw_conv1d_en = model.encoder.layers[1].weights[0]\n",
    "        kw_dense_en = model.encoder.layers[3].weights[0]\n",
    "        kw_dense_de = model.decoder.layers[0].weights[0]\n",
    "        kw_conv1dtrs_de = model.decoder.layers[2].weights[0]\n",
    "        kw_conv1dtrs2_de = model.decoder.layers[3].weights[0]\n",
    "    \n",
    "        loss_r = (loss_l2(kw_conv1d_en)\n",
    "                +loss_l2(kw_dense_en)\n",
    "                +loss_l2(kw_dense_de)\n",
    "                +loss_l2(kw_conv1dtrs_de)\n",
    "                +loss_l2(kw_conv1dtrs2_de))\n",
    "    \n",
    "    return err, elbo\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)[0]\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145163db",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "* Start by iterating over the dataset\n",
    "* During each iteration, pass the image to the encoder to obtain a set of mean and log-variance parameters of the approximate posterior $q(z|x)$\n",
    "* then apply the *reparameterization trick* to sample from $q(z|x)$\n",
    "* Finally, pass the reparameterized samples to the decoder to obtain the logits of the generative distribution $p(x|z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07973d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 3\n",
    "num_examples_to_generate = 16\n",
    "num_examples_to_validate = 1000\n",
    "\n",
    "name_latent = str('%d' % latent_dim)\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = VAE(latent_dim, q_rs_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa70201b",
   "metadata": {},
   "source": [
    "### Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004cff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a sample of the test set for generating output images\n",
    "assert batch_size_test >= num_examples_to_generate\n",
    "for test_batch in test_dataset.take(1):\n",
    "    test_sample = test_batch[0:num_examples_to_generate, :]\n",
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second test set\n",
    "for test_batch in test_dataset.take(1):\n",
    "    test2_sample = test_batch[num_examples_to_generate:num_examples_to_generate+num_examples_to_validate, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c41bcfa",
   "metadata": {},
   "source": [
    "### Generating images\n",
    "\n",
    "* After training, it is time to generate some images\n",
    "* Start by sampling a set of latent vectors from the unit Gaussian prior distribution $p(z)$\n",
    "* The generator will then convert the latent sample $z$ to logits of the observation, giving a distribution $p(x|z)$\n",
    "* Plot $p(x|\\mathbb{E}(z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8cc11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "    mean, logvar = model.encode(test_sample)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    predictions = model.sample(z)\n",
    "    \n",
    "    ## Decoded Means\n",
    "    z0 = mean\n",
    "    predictions_0 = model.sample(z0)\n",
    "        \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.plot(q_rs,f_out(test_sample[i,:]),'k')\n",
    "        plt.plot(q_rs,f_out(predictions[i,:]),'.c')\n",
    "        plt.plot(q_rs,f_out(predictions_0[i,:]),'b')        \n",
    "        \n",
    "        #plt.axis('off')\n",
    "        plt.ylim(0, 3)\n",
    "\n",
    "    # tight_layout minimizes the overlap between 2 sub-plots\n",
    "    pngname = './figures_SQ_cVAE_MSE/image_SQ_cVAE_MSE' + name_latent + '_{:04d}.png'\n",
    "    plt.savefig(pngname.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2890e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_and_save_images(model, 0, test_sample)\n",
    "\n",
    "err_test_epoch = np.zeros(epochs)\n",
    "err_test2_epoch = np.zeros(epochs)\n",
    "err_train_epoch = np.zeros(epochs)\n",
    "ELBO_train_epoch = np.zeros(epochs)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for train_x in train_dataset:\n",
    "        train_step(model, train_x, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for test_x in test_dataset:\n",
    "        loss(compute_loss(model, test_x)[1])\n",
    "    elbo = -loss.result()\n",
    "    ELBO_train_epoch[epoch-1] = elbo\n",
    "    \n",
    "    # loss\n",
    "    err_test = compute_loss(model, test_sample)[0]\n",
    "    err_train = compute_loss(model, train_x)[0]\n",
    "    err_test2 = compute_loss(model, test2_sample)[0]\n",
    "    err_test_epoch[epoch-1] = err_test\n",
    "    err_test2_epoch[epoch-1] = err_test2\n",
    "    err_train_epoch[epoch-1] = err_train\n",
    "        \n",
    "    display.clear_output(wait=False)\n",
    "    print('Epoch: {}, Test set ELBO: {:.6}, err:{:.6}, time elapse for current epoch: {}'.format(epoch, elbo, err_train, end_time - start_time))\n",
    "    generate_and_save_images(model, epoch, test_sample)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e09b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "errname = './figures_SQ_cVAE_MSE/err_SQ_cVAE_MSE' + name_latent + '_{:04d}.png'\n",
    "fig2 = plt.figure(figsize=(8, 6))\n",
    "plt.plot(err_test2_epoch,'-r')\n",
    "plt.plot(err_train_epoch,'-g')\n",
    "plt.yscale('log')\n",
    "#plt.ylim(4e-3, 1e-1)\n",
    "plt.savefig(errname.format(epoch))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELBOname = './figures_SQ_cVAE_MSE/ELBO_SQ_cVAE_MSE' + name_latent + '_{:04d}.png'\n",
    "fig2 = plt.figure(figsize=(8, 6))\n",
    "plt.plot(ELBO_train_epoch,'-g')\n",
    "#plt.yscale('log')\n",
    "#plt.ylim(4e-3, 1e-1)\n",
    "plt.savefig(ELBOname.format(epoch))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dddb8c3",
   "metadata": {},
   "source": [
    "### Display an animated GIF of all the saved images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846591e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = './figures_SQ_cVAE_MSE/SQ_cVAE_MSE' + name_latent + '.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('./figures_SQ_cVAE_MSE/image_SQ_cVAE_MSE*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a58bda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c571f567",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = './saved_model/SQ_cVAE_MSE/'\n",
    "if not os.path.isdir(export_path):\n",
    "    os.mkdir(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caead54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_conv_stride2'\n",
    "export_name = export_path + model_name\n",
    "model.save_weights(export_name, overwrite=True, save_format=None, options=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d6c60",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc390e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = to_tf(f_inp(sq_mask[0:sq.shape[0]]))\n",
    "mean, logvar = model.encode(x)\n",
    "z = model.reparameterize(mean, logvar)\n",
    "x_logit = model.sample(z)\n",
    "z = z.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948553b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(z[:,0], z[:,1], z[:,2], c=lnA)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee8e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
